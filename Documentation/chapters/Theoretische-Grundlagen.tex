\chapter{Theoretische Grundlagen}
\section{Machine Learning}
\label{chap:t_ml}
Machine Learning ist ein Teilbereich der künstlichen Intelligenz. Der Begriff
`künstliche Intelligenz' beschreibt eine Maschine, die menschliche Tätigkeiten
nachahmt. Mit Maschine ist in den aller meisten Fällen ein Computer,
beziehungsweise das Computerprogramm, das diesen steuert, gemeint. Bei Machine
Learning handelt es sich ebenfalls um Computerprogramme. Es sind also eine
spezifische Form von Algorithmen. Machine Learning Algorithmen entwickeln (oder
erlernen) eine Mustererkennung durch die Analyse von Daten. Mustererkennung
bedeutet hier, dass der Algorithmus Kriterien entwickelt, wonach er bezogen auf
die gegebenen Daten Aussagen oder Vorhersagen treffen kann.

Ein Beispielproblem für einen Machine Learning Algorithmus ist die Erkennung von
handschriftlichen Zahlen. Ein Algorithmus soll also mit der Eingabe eines Bildes
mit einer handschriftlichen Zahl eine korrekte Aussage treffen, um welche Zahl
es sich handelt. Mit anderen Worten soll die Ausgabe des Algorithmus der Zahl
entsprechen, die auf dem Bild der Eingabe zu sehen ist.

Jeder Algorithmus, der dieses Problem löst, gehört zum Überbegriff der
küntlichen Intelligenz. Die Erkennung und Einordnung von handschriftlichen
Zahlen ist eine menschliche Tätigkeit, beziehungsweise eine Leistung der
menschlichen Intelligenz. [Quelle]. Machine Learning Algorithmen sind ein Ansatz
für die Umsetzung eines solchen Algorithmus.

\subsection*{Funktionsweise eines Machine Learning Algorithmus}
Dieser Abschnitt beschreibt die Funktionsweise einen Machine Learning
Algorithmus, der das im letzen Abschnitt genannte Problem (siehe ML) löst.
Vorerst benötigt der Algorithmus die Daten, die analysiert werden. Die
allermeisten Machine Learning Algorithmen die dieses Problem lösen verwenden das
MNIST Datenset. Das MNIST Datenset wurde vom NIST (National Institute of
Standards and Technology) in Amerika erstellt und beinhaltet 70'000 Bilder von
hangeschriebenen Zahlen. Jedes Bild hat eine auflösung von $28\times28$ Pixeln.

Ein Machine Learning Algorithmus durchläuft eine Trainingsphase, bevor er das
Problem erfolgreich lösen kann. Vor dieser Trainingsphase kann der Algorithmus
keine verlässlichen Aussagen über die Eingabedaten treffen. Nach der
Trainingsphase folgt eine Testphase. Dabei wird die Genauigkeit gemessen, also
die Wahrscheinlichkeit, mit der der Algorithmus die richige Lösung zur Eingabe
liefert. Nur in den seltensten Fällen erreicht diese Genauigkeit $100\%$. Der
Algorithmus garantiert somit nicht die richtige Lösung

Während der Trainingsphase werden einem Machine Learning Algorithmus immer
wieder Bilder als Eingabe übergeben, aus denen der Algorithmus eine Aussage
trifft. Am Anfang der Trainingsphase ist diese Aussage nicht verlässlich und in
vielen Fällen falsch. Zu der übergebenen Eingabe ist die korrekte Lösung bereits
im Voraus bekannt. Falls die Vorhersage, die vom Algorithmus getroffen wurde,
nicht mit der korrekten Lösung übereinstimmt, passt sich der Algorithmus
automatisch und selbstständig an. Durch diese Anpassung wird es bei einer
nächsten, ähnlichen Eingabe wahrscheinlicher, dass der Algorithmus die korrekte
Vorhersage trifft. 

Ein Machine Learning Algorithmus trifft also Vorhersagen bezogen auf eine
Eingabe und kann sich selbst während der Trainingsphase automatisch Anpassen.
Diese Funktionalität erhalten Machine Learning Algorithmen durch künstliche
neuronale Netze.

\subsection*{künstliche neuronale Netze}

Ein neuronales Netz ist, im biologischen Sinne, "eine beliebige Anzahl Neuronen,
die miteinander Verbunden sind" (Wikipedia). Ein Beispiel für ein neuronales
Netz ist das menschliche Gehirn, worauf die kognitive Fähigkeit des Menschen
beruht. Künstliche Neuronale Netze stellen ein Modell von neuronalen Netzen dar.
Sie sind somit theoretische Abbildungen der Realität, die in Programmcode
überführt werden können. Dadurch simuliert ein Computer eine vereinfachte Form
eines neuronalen Netz. In anderen Worten simuliert der Computer eine
vereinfachte Form der menschlichen Intelligenz. Diese Arbeit behandelt nur
künsltiche neuronale Netze, nicht aber biologische. Somit handelt es sich bei
jedem erwähnten neuronalen Netz, um ein künstliches neuronales Netz 

Der Grundbaustein eines neuronalen Netzes ist das Neuron. Im Modell stellt
dieses ein Objekt dar, das eine beliebiege Anzahl \textbf{Eingaben} hat und
daraus eine einzige \textbf{Ausgabe} trifft. Eingaben und Ausgaben sind hierbei
immer rationale Zahlen. Die Ausgabe des Neurons ist grundsätzlich entweder 0
oder 1. Die Ausgabe ist 1, wenn die Summe der Eingaben einen vorgegebenen
\textbf{Schwellenwert} des Neurons überschreiten. Ansonsten ist die Ausgabe
gleich 0. Jede Eingabe hat ein \textbf{Gewicht}, das Ebenfalls durch eine
rationale Zahl repräsentiert ist. Bevor die Eingaben addiert werden, wird jede
Eingabe mit dem zugehörigen Gewicht multipliziert. Die Grösse des Gewichts
bestimmt somit den Einfluss der zugehörigen Eingabe auf die Ausgabe des Neurons.
Es gibt verschiedene Arten von Neuronen. Diese Erklärung bezieht sich auf die
einfachste Form, das Perceptron. Neuronale Netze verwenden kompliziertere
Varianten, wie das Sigmoid-Neuron. 

Neuronale Netze sind Verbindungen dieser Neuronen. Dabei dient die Ausgabe eines
Neurons als eine Eingabe in ein anderes Neuron. Da ein Neuron mehrere Eingaben
haben kann, bilden sich sehr unterschiedliche Anordnungen. die Neuronen sind in
Ebenen geordnet. Es gibt die \textbf{Eingabe-Ebene}. Es handelt sich dabei um
die eigentliche Eingabe des Problems, das der Machine Learning Algrorithmus
lösen sollte. Im Beispielproblem (siehe oben) bestände die Eingabe-Ebene aus
28x28 Neuronen, wobei jedes Neuron die Graustufe (durch einen Wert von 0 bis
255) eines Pixels im Bild beschreibt. Die letzte Ebene ist die
\textbf{Ausgabe-Ebene} Im Beispielproblem soll der Machine Learning Algorithmus
die korrekte Zahl zwischen 0 und 9 ausgeben. Die Ausgabe-Ebene hat im Beispiel
10 Neuronen, wobei jedes Neuron eine der Lösungen (also eine Zahl von 0 bis 9)
repräsentiert. Dasjenige Neuron der Ausgabe mit dem höchsten Wert entspricht der
Entscheidung des Algorithmus. (Die letzte Entscheidung gehört also nicht mehr
zum neuronalen Netz, basiert aber auf dessen Ergebnis). Zwischen der
Eingabe-Ebene und der Ausgabe-Ebene gibt es häufig weitere Ebenen an Neuronen,
genannt \textbf{versteckte-Ebenen}. Mehr Neuronen und mehr Ebenen bedeuten
komplexere neuronale Netze, die in der Lage sind, komplexere Vorhersagen zu
treffen. Ab mehr als einer versteckten Ebene werden Machine Learning Algorithmen
als Deep Learning Algorithmen bezeichnet.

Ein Machine Learning Algorithmus passt während der Trainingsphase (siehe oben)
einzelne Gewichte im neuronalen Netz an. Dadurch wird die Ausgabe verändert. 


\subsection*{Arten von Machine Learning}

Es gibt drei Arten von Machine Learning Algorithmen: Supervised Learning (überwachtes Lernen), Unsupervised Learning (unüberwachtes Lernen) und
Reinforcement learning (bestärktes Lernen). Nachfolgend werden supervised Learnig und unsupervised learning
kurz erklärt. Die Erklärung vom Reinforcement learning folgt im nächsten Kapitel (siehe unten)

Das Beispielproblem (siehe oben) wird durch einen Supervised Learning
Algorithmus gelöst. Typisch sind dabei Trainingsdaten, bei denen die korrekte
Lösung bereits im Voraus bekannt ist. Der Algorithmus trainiert also auf
Vorhersagen, die zuvor als richtig definiert wurden. Der Algorithmus passt sich
somit den Vorstellungen derjenigen Person an, die die Daten präpariert und die
Lösungen definiert hat.


Unsupervised learning ist das Gegenteil von Supervised Learning. Bei den
Trainingsdaten ist keine vorgegebene Lösung bekannt. Stattdessen soll der
Algorithmus selbstständig Muster in den Daten erkennen. So soll der Algorithmus
eine Einordnung der Daten nach selbstdefinierten Kriterien vornehmen. Im
Gegensatz zu Supervised Learning versucht der Entwickler hier nicht, den
Algorithmus nach seinen eigenen Vorstellungen anzupassen. Stattdessen versucht
der Entwickler aus den Ergebnisen des Algorithmus neue Schlüsse zu ziehen.
Beispiele für Unsupervised Learning sind einige Algorithmen hinter der
Personalisierung von Werbung. Diese Algorithmen versuchen Personen anhand von
gesammelten Benutzerdaten in Gruppen zu ordnen, die gewisse Produkte
interessieren. Den Entwicklern ist dabei im Voraus unklar, nach welchen
Kriterien diese Einteilung vorgenommen wird. 

\section{Reinforcement Learning}
\label{chap:t_rl}

Reinforcement Learning bedeutet vereinfacht Lernen durch Interaktion mit der
Umgebung. (Sutten, Barto)  Genauer lernt ein Machine Learning Algorithmus durch
die Interaktion mit einer Umgebung, wie er sich in dieser Verhalten soll.

Reinforcement Learning Algorithmen führen also die Umgebung ein. In Supervised
Learning und Unsupervised Learning werden Daten bereitgestellt, aus denen der
Machine Learning Algorithmus "lernt". Bei einer Umgebung sind diese Daten
allerdings im Voraus nicht bekannt. Das kommt daher, dass eine Umgebung häufig
zu viele verschiedene Zustände einnehmen kann, als dass diese im Vorraus erfasst
werden könnten. Der Machine Learning Algorithmus kann trotzdem aus der Umgebung
lernen, indem dieser selbt als Element der Umgebung angesehen wird und so mit
ihr interagieren kann.

Die echte Welt kann ebenfalls als eine Umgebung angesehen werden. Der Mensch
wäre in diesem Fall der Machine learning Algorithmus. Der Mensch erlernt zum
Beispiel das Laufen, indem er mit der Welt interagiert. Eine Interaktion wäre
hier zum Beispiel das Hinfallen. Dadurch erlernt der Mensch das Verhalten der
Schwerkraft, welches zu diesem Fall geführt hat. Der Mensch lernt dieses
Verhalten durch eigene Erfahrungen, ohne dass ihm vorher bereits Daten über die
Welt gezeigt wurden. 

Reinforcement Learning Algorithmen stellen dieses Lernverhalten nach. So
verwenden Roboter, die das Laufen lernen sollen häufig diesen Ansatz. Die
Umgebung ist für den Reinforcement Learning Algorithmus im Roboter tatsächlich
die echte Welt. Bei der Umgebung kann es sich aber auch um eine
Computersimulation handeln.

\subsection*{Aufbau und Funktionsweise}

Dieser Abschnitt umfasst eine genauere Erklärung eines Reinforcement Learning
Algorithmus (Deep Q-Learning) unter der Verwendung der korrekten Fachbegriffe.

Ein Reinforcement Learning Algorithmus umfasst eine Umgebung und einen Agenten.
Der Agent ist dasjenige Element in der Umgebung, welches mit dieser interagiert
und daraus lernt. Der Agent umfasst ein Neuronales Netz. Die Eingabe in dieses
Netz ist die \textbf{Beobachtung} der Umgebung, also diejenigen aktuellen Daten
aus der Umgebung, die für den Agenten relevant sind. Die Ausgabe des Netzes
entspricht einer gewissen Anzahl Neuronen, die alle einen bestimmten Wert (den
\textbf{Q-Wert}) haben, der jeweils von der Eingabe abhängt. Jedes Neuron
repräsentiert eine Aktion, wobei jenes Neuron mit dem höchsten Q-Wert als die
`beste' Aktion angesehen wird. Der Agent kann somit nur eine festgelegte Anzahl
verschiedener Aktionen ausführen, die durch die Anzahl der Neuronen der Ausgabe
definiert ist. Der Agent führt in den meisten Fällen diejenige Aktion aus, die
als die beste definiert ist. Mit einer kleinen Wahrscheinlichkeit führt er
allerdings eine zufällige Aktion aus. Die Hoffnung dahinter ist, dass sich die
zufällige Aktion schlussendlich als noch besser herausstellt 

Nachdem der Agent eine Aktion ausführt, wird der Einfluss dieser Aktion auf die
Umgebung gemessen. Dabei bestimmt eine \textbf{Reward-funciton}, ob die Aktion
positiv oder negativ auf die Umgebung wirkt. Das wird durch eine Zahl
ausgedrückt. Umso grösser die Zahl, desto positiver ist der Effekt auf die
Umgebung und umgekehrt. Diese Zahl wird Belohnung oder \textbf{Reward} genannt.
Der Q-Wert der ausgeführten Aktion wird schliesslich bezogen auf den Reward
angepasst (Durch die Bellman Gleichung). Ein Kleinerer Reward führt zu einem
kleineren Q-Wert für die Aktion, wodurch diese in Zukunft weniger wahrscheinlich
gewählt wird. Umgekehrt macht ein grösserer Reward die Aktion, die diesen
ausgelöst hat, in Zukunft wahrscheinlicher. Nach der Anpassung des Q-Werts wird
das Neuronale Netz auf diese neue Ausgabe trainiert. Die Gewichte im Neuronalen
Netz werden also so angepasst, dass die Ausgabe einer ähnliche Eingabe in
Zukunft näher an den neu angepassten Q-Werten ist als an den alten.

\section{Verwandte Arbeiten und Themen}
\label{chap:t_verwandt}
Es gibt verschiedene Ansätze, um ein Computerprogramm die menschliche Tätigkeit
des Nachzeichnens verrichten zu lassen. Diese Ansätze werden in verschiedenen
wissenschaftlichen Arbeiten verfolgt. Ein häufiger Ansatz ist "Stroke-Based
Rendering", wobei Bilder durch das Platzieren von Elementen wie Strichen
gezeichnet werden. Beispiele für Arbeiten, die diesen Ansatz verwenden sind\dots
Stroke-Based Rendering unterscheidet sich von menschlichem Zeichnen dadurch,
dass kein Stift geführt wird. Stattdessen können die Elemente zu jedem Zeitpunkt
an einer willkürlichen Position auf der Zeichenfläche platziert werden.

Andere Ansätze simulieren die Führung eines Stiftes. Das Computerprogramm kann
also nicht zu jedem Zeitpunkt an jedem Ort Zeichnen. Stattdessen ist es an eine
Position (einen Stift) gebunden, welche mit einer gewissen Geschwindigkeit
bewegt werden kann. Das ist eine Einschränkung, die auch auf menschliches
Zeichnen mit einem Stift zutrifft. Ein Beipiel von diesem Programm ist Doodle-SDQ von Tao Zhou et Al (2018)

\subsection*{Doodle-SDQ}
Doodle-SDQ ist ein Programm, das durch Deep Q Learning erlernt hat, Strichbilder
aus dem Google Quick-Draw Datenset nachzuzeichnen. Das Programm stammt aus der
Arbeit `Learning to Doodle with Deep Q-Networks and Demonstration Strokes' von
Tao Zhou et Al. aus dem Jahr 2018. Wie der Titel beschreibt basiert das Programm
auf dem Deep Q-Learning Algorithmus (siehe oben). `Demonstration Strokes' ist
ein weiteres verfolgtes Konzept in der Arbeit. Dieses gehört allerdings nicht
zum Bereich von Reinforcement learning, sondern ist vereinfacht gesagt eine
Methode zur Optimierung des Algorithmus. Die Folgende Erklärung bezieht sich
daher nur auf den Deep Q-Learning Algorithmus.

Das Quick-Draw Datenset von Google beinhaltet Bilder von verschiedenen,
menschlichen Strichzeichnungen. Das Programm versucht, diese Bilder
nachzuzeichnen. Dazu werden die Bilder zuerst auf eine einheitliche Grösse von
84x84 Pixeln komprimiert. Der Agent kann sich auf dieser Fläche bewegen und
Zeichnen. Es handelt sich bei dieser Zeichenfläche um die Umgebung des Agenten
Der Agent kann sich mit einer Aktion auf einen beliebigen Pixel in einem 11x11
Feld, in dessen Zentrum er ist, bewegen. Dabei kann der Agent entweder zwischen
seiner alten und seiner neuen Position Zeichnen oder nicht. Der Agent kann somit
insgesamt 2x11x11 Aktionen ausführen. Diese Anzahl Aktionen entspricht
gleichzeitig der Anzahl Neuronen in der Ausgabe des neuronalen Netzes. Die
Eingabe in das Netz, also die Beobachtung der Umgebung wird in zwei Teile
gegliedert: Ein globaler Teil (global channel) und ein lokaler Teil (local
channel). Der Globale Teil umfasst das vorgegebene Bild (die Vorlage), das bis
anhin gezeichnete Bild, die aktuelle Position des Agenten und die Angabe, ob der
Agent gerade am Zeichnen ist oder nicht. Der Lokale Teil umfasst nur noch das
11x11 Feld vom vorgegebenen und dem bis anhin gezeichneten Bild, das sich direkt
um den Agenten befindet. Diese erneute Eingabe des kleineren Feldes in das Netz
ist notwendig, weil die unmittelbare Umgebung des Agenten für die Entscheidung
der nächsten Aktion sehr relevant ist. Der Reward wird durch die Anzahl der neu
übereinstimmenden Pixeln zwischen der Vorlage und dem bis anhin
gezeichneten Bild bestimmt. 

\section{Git und GitHub}
\label{chap:git_github}
Git und Github sind weit verbreitete Hilfsmittel für Entwickler. Bei Git handelt
es sich um ein Programm, während Github ein Service ist, um Projekte, welche mit
Git verwaltet werden, öffentlich zugänglich zu machen. GitHub bringt zusätzlich
viele weitere nützliche Features, welche die Zusam\hyp{}menarbeit erleichtern. Die
genaue Funktion und das Zusammenspiel dieser beiden Hilfsmittel wird nachfolgend
erläutert.

\subsection*{Git}
Git ist ein Programm, welches Veränderungen im Code eines Projektes erkennt und
zwischen Versionen speichert. Dieses Konzept nennt sich Version Control. Es
wurde 2005 von Linus Torvald für die Entwicklung des Linux Kernels entwickelt.
Der Unterschied zwischen Git und anderer Version Control Software ist, dass
jeder, der am Code arbeiten will, den gesamten Code, auch Source Code genannt,
braucht. Dadurch ist das System dezen\hyp{}tralisierter.
\cite{noauthor_git_2021}

Git ist nicht die einzige Version Control Software. Andere Beispiele wären:
Azure DevOps Server, Helix Core, AWS CodeCommit, Subversion, Plastic SCM, etc. 
\cite{noauthor_git_nodate-1}

\subsection*{GitHub}
Es wird häufig gedacht, dass Git und GitHub dasselbe sei, was allerdings nicht
richtig ist. Git ist die Version Control Software, die das Verwalten der
verschiedenen Versionen ermöglicht. GitHub ist ein Service, der es ermöglicht,
die von Git erstellten Repositories als Cloud Lösung bereit zu stellen. Durch
diesen Cloud Service von GitHub ist es möglich, gemeinsam an den verschiedenen
Versionen des Source Codes zu arbeiten. GitHub stellt dafür auch eine Webseite
zur Verfügung, um die Projekte zu verwalten. Dabei ist Git für die Bearbeitung
der Repositiories zuständig, während GitHub die Repositories den anderen
Entwicklern bereitstellt.
\cite{noauthor_github_2021} 

``GitHub wurde von Chris Wanstrath, PJ Hyett, Scott Chacon und Tom Preston-Werner
[...] entwickelt und im Februar 2008 gestartet'' \cite{noauthor_github_2021}.
2018 wurde das Unternehmen von Microsoft gekauft. GitHub ist heute eine der
grössten Plattformen für Open Source Projekte und das Zusammenarbeiten an
Software. Projekte können ohne Umstände für Leute auf der ganzen Welt zugänglich
gemacht werden. Wenn Entwickler an einem öffentlichen Projekt auf Github
Interesse finden, können sie selbst daran weiterarbeiten. 
\cite{noauthor_github_2021}

Um die Codequalität trotz einer grossen Menge an alleinstehenden Ent\hyp{}wicklern zu
gewährleisten, gibt es auf GitHub einige Tools, die das Zusamm\hyp{}enarbeiten, das
Kommunizieren und das Bewerten von Code vereinfachen. Einige dieser Tools werden
nachfolgend vorgestellt.

GitHub ist nicht die einzige Plattform, welche das Hosten von Git Repositories
erlaubt. Es gibt weitere Konkurrenten, wie: GitLab, Bitbucket, GitBucket, etc.
\cite{noauthor_top_2021}
