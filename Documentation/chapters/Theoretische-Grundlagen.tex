\chapter{Theoretische Grundlagen}

\section{Machine Learning}
\label{chap:t_ml}
Teilbereich künstliche Intelligenz (Künstliche Intelligenz ist Maschine, die
menschliche Tätigkeiten nachmacht) Maschine = Computer -> Computerprogramm
(Algorithmus) Machine Learning ist Überbegriff -> Computerprogramme, die eine
Mustererkennung entwickeln. Durch Analysieren von Daten. KI lernt Vorhersagen

Beispiel Zahlenerkennung: Beispiel für Künstliche Intelligenz Bild einer
handschriftlichen Zahl wird Programm übergeben (Input) Das Programm bestimmt, um
welche Zahl es sich handelt. Programm gibt Zahl aus

Künstliche Intelligenz weil das Erkennen von Zahlen menschlich ist.

Unterschied machine Learning: KI lernt von Grund auf, Zahlen zu Erkennen Anfang
wird allermeistens Falsch sein

KI lernt durch die Analyse von Daten. -> Trainingsdaten. Dabei ist bekannt, was
die richtige Lösung zu den gegebenen Daten ist. So erfährt die KI, wenn sie
falsch liegt. Programm kann sich bezogen auf Erfahrung selbst anpassen.
Anpassungen möglichst so, dass Vorhersagen in Zukunft besser sind.

Nachdem KI mit Trainingsdaten verbessert wurde, sollte diese auch für neue Daten
möglichst genaue Vorhersagen machen.

Nächste Frage: Wie trifft KI entscheidungen, und wie kann sie sich selbst
Anpassen? -> Antwort Neuronale Netze


\subsection*{künstliche neuronale Netze}

Grundbaustein eines neuronalen Netzes sind Neuronen, (modelle eines biologischen
Neurons) mehrere Eingaben, eine Ausgabe. Eingaben sind verschieden wichtig (sind
gewichtet) Wenn Eingaben zusammen einen gewissen Grenzwert überschreiten,
"Feuert" das Neuron. 1 anstelle von 0 wenn es nicht feuert (vereinfachte
Erklärung eines Sigmoid-Neuron)

Es gibt Neuronen mit Eingaben in KI. Diese haben verbindungen zu weiteren
Neuronen in der nächsten Ebene (versteckte Ebene). Die Letzte Ebene des Netzes
hat die Ausgabe Neuronen (mit MNIST Beispiel erklären. Im Beispiel sind es 10
Neuronen, wobei jedes Neuron eine andere Zahl von 0-9 darstellt. Diese Neuronen
haben keine Ausgabe mehr, die für das neuronale Netz relevant ist. Die
Entscheidung basiert in diesem Fall lediglich darauf, welches der 10
Ausgabeneurenen den höchsten Wert enthält. Die Zahl, die dieses Neuron
repräsentiert, wird dann als die Entscheidung des Neuronalen Netzes angesehen).
mehr als eine versteckte Ebene ermöglicht schwierigere Entscheidungen -> Deep
learning

Der Lernprozess findet durch eine anpassung von Einzelnen Gewichten der
Eingaben, wenn die KI eine falsche Entscheidung trifft. Dadurch soll die
Entscheidung so angepasst werden, dass sie im nächsten Fall besser ausfällt

Neuronale Netze sind in Ebenen aufgeteilt. Eingabe Ebene, Ausgabe Ebene. Und
Ebenen dazwischen. Versteckte Ebenen. Sobald es mehr als eine Ebene an
versteckten Ebene gibt, nennt man es Deep learning.

\subsection*{Arten von Machine Learning}

Es gibt 3 Arten von Machine Learning Algorithmen: supervised, unsupervised, reinforcement
learning. Nachfolgend werden supervised und unsupervised learning kurz erklärt.
Reinforcement learning im nächsten Kapitel, weil für Methode hinter Arbeit
wichtig

Erkennung von Handschriftlichen Daten ist supervised learning ->
Typisch sind Trainingsdaten, bei denen die richtige Lösung bekannt ist.
Algorithmus wird also auf Vorhersagen trainiert, die vorher als richtig
angesehen wurden. Gewissermassen also Algorithmus in Freiheit seiner Lösung
eingeschränkt und passt sich den Vorstellungen von demjenigen an, der die Daten präpariert hat (Also die seiner Meinung nach richtigen Lösungen) an. Wird also überwacht.

unsupervised learning ist das Gegenteil. Wird nicht auf vorgegebene Lösungen
trainiert. Stattdessen soll Algorithmus selbstständig Muster in Daten erkennen.
Es wird also im voraus nicht definiert, was der Algorithmus lernen soll.
Angewendet für Gliederungen und Klassifikationen in Datensätzen, wo Menschen den
Überblick verlieren würden. Ausserdem, weil im voraus komplett unklar ist, wie
der Algorithmus die Daten verarbeitet, können neue Muster erkannt werden.
Muster, die von Menschen bisher übersehen wurden 







\section{Reinforcement Learning}
\label{chap:t_rl}

Reinforcement Learning bedeutet vereinfacht lernen durch Interaktion mit der
Umgebung (Sutten, Barto) 

Es wird also die Umgebung eingeführt. In supervised und
unsupervised werden Daten bereitgestellt, aus denen der Algorithmus "lernt".
Reinforcement Learning Algorithmen lernen nicht aus bereitgestellten Daten, sondern aus ihrer Umgebung.

diese Umgebung kann sich gegenüber der Zeit verändern und wird durch
verschiedene Faktoren beeinflusst. Die Echte Welt dient auch als Umgebung. Eine
Umgebung mit der der Mensch interagiert, wodurch er Erfahrungen sammelt und
lernt. Comupterprogramme, wie ein Reinforcement Learning Algorithmus, können
aber nicht mit der echten Welt interagieren. Stattdessen dienen Computersimulationen als Umgebung.

\subsection*{Aufbau und Funktionsweise}

Wie erwähnt braucht ein Reinforcement Algorithmus eine Umgebung, also eine
Computersimulation. Der Lernprozess findet durch die Interaktion mit dieser
Umgebung statt. Diese Interaktion wird durch einen sogenannten Agent ausgeführt.
Der Agent ist durch die Umgebung beeinflusst, kann umgekehrt aber auch die
Umgebung durch seine Aktionen verändern. Je nachdem wie die Aktionen des Agents
auf die Umgebung wirken, kann der Agent belohnt oder bestraft werden. Dabei muss
vordefiniert sein, was belohnt wird und was bestraft wird. Schlussendlich lernt
der Agent durch diese Belohnungen und Bestrafungen, wie er sich in zukünftigen
ähnlichen Situationen verhalten soll. 

Reinforcement Learning ist ein Überbegriff für verschiedene Algorithmen, die
nach dem gerade beschriebenen Prinzip arbeiten. Der Deep Q-Learning Algorithmus
ist ein Beispiel für Die genaue Funktionsweise eines Reinforcement Learning
Algorithmus, der in dieser Arbeit implementiert ist.

\subsection*{Deep Q-Learning}



Die hier beschriebene Umgebung hat also
Ähnlichkeiten mit der echten Welt




Verschiedene Arten
Ziel, Anwendungsbereich

Architektur<R


\section{Verwandte Arbeiten und Themen}
\label{chap:t_verwandt}

Ein verwandtes Thema dieser Arbeit ist die Robotik. Ein Roboter ist laut der
Definition eine `Apparatur, die bestimmte Funktionen eines Menschen ausführen
kann' (Duden). Das Nachzeichnen von Strichbildern ist ebenfalls eine menschliche
Tätigkeit. Diese Arbeit untersucht allerdings nur das Computerprogramm, welches
diese Tätigkeit verrichten kann. Das Ziel ist es also nicht, eine Apperatur zu
bauen, die vom Computerprogramm gesteuert werden würde.

Es gibt verschiedene Ansätze, um ein Computerprogramm die menschliche Tätigkeit
des Nachzeichnens verrichten zu lassen. Ein häufiger Ansatz ist "Stroke-Based
Rendering", wobei Bilder durch das Platzieren von Elementen wie Strichen
gezeichnet werden. Beispiele für Arbeiten, die diesen Ansatz verwenden sind\dots
Stroke-Based Rendering unterscheidet sich von menschlichem Zeichnen dadurch,
dass kein Stift geführt wird. Stattdessen können die Elemente zu jedem Zeitpunkt
an einer willkürlichen Position auf der Zeichenfläche platziert werden.

Andere Ansätze simulieren die Führung eines Stiftes. Das Computerprogramm kann
also nicht zu jedem Zeitpunkt an jedem Ort Zeichnen. Stattdessen ist es an eine
Position (einen Stift) gebunden, welche mit einer gewissen Geschwindigkeit
bewegt werden kann. Das ist eine Einschränkung, die auch auf menschliches
Zeichnen mit einem Stift zutrifft. Ein Beipiel für ein Computerprogramm, das diese Art des Zeichnens Nachahmt ist
Doodle-SDQ von ...


\subsection*{Doodle-SDQ}
Doodle-SDQ ist ein Programm, das durch Deep Q Learning erlernt hat, Strichbilder
aus dem Google Quick-Draw Datenset nachzuzeichnen. Ist in der Freiheit des
Zeichnens eingeschränk\indent 

Architektur: Agent = Stift. Umgebung = Zeichenfläche. Speichert Position von
Agent, das zu Nachzeichnende Bild, das was bis jezt gezeichnet wurde und ob
Stift gerade vom Blatt gehoben ist. Die Belohnung/Bestrafung ist der Grad der
Ähnlichkeit zwischen Bildern. Die Unmittelbare Umgebung des Agenten, in dem er
sich in einem Schritt bewegen kann, wird in das neuronale Netz noch ein weiteres
Mal eingegeben, wodurch darauf ein Fokus gelegt wird. Ausgabe des neuronalen
Netz ist eine der Aktionen die der Agent ausführen kann
R

\section{Git und GitHub}
\label{chap:t_git}



