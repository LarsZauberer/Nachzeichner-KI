{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tic Tac Toe\n",
    "Ein simpler Test von RL mit einem 2D Environnement, wobei die States 2D sind. Das würde für unser Drawing System ein einfachreres System ermöglichen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.environments import tf_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.environments import wrappers\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.drivers import py_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import reverb_replay_buffer\n",
    "from tf_agents.replay_buffers import reverb_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.utils import common\n",
    "from tf_agents.environments import utils\n",
    "\n",
    "import reverb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tic Tac Toe Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game(py_environment.PyEnvironment):\n",
    "    def __init__(self):\n",
    "        self._action_spec = array_spec.BoundedArraySpec(\n",
    "        shape=(2,), dtype=np.int32, minimum=[0, 0], maximum=[2, 2], name='action')\n",
    "        self._observation_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(3, 3), dtype=np.int32, minimum=[[0, 0, 0], [0, 0, 0], [0, 0, 0]], maximum=[[2, 2, 2], [2, 2, 2], [2, 2, 2]], name='observation')\n",
    "        self._state = [[0, 0, 0], [0, 0, 0], [0, 0, 0]]\n",
    "        self._episode_ended = False\n",
    "\n",
    "    def action_spec(self):\n",
    "        return self._action_spec\n",
    "\n",
    "    def observation_spec(self):\n",
    "        return self._observation_spec\n",
    "\n",
    "    def _reset(self):\n",
    "        self._state = [[0, 0, 0], [0, 0, 0], [0, 0, 0]]\n",
    "        self._episode_ended = False\n",
    "        return ts.restart(np.array([self._state], dtype=np.int32))\n",
    "\n",
    "    def _step(self, action):\n",
    "\n",
    "        if self._episode_ended:\n",
    "            # The last action ended the episode. Ignore the current action and start\n",
    "             # a new episode.\n",
    "            return self.reset()\n",
    "\n",
    "        reward = 0.0\n",
    "        #\n",
    "        # Tic Tac Toe Logic\n",
    "        #\n",
    "        \n",
    "        if self._state[action[0]][action[1]] > 0:\n",
    "            reward -= 1\n",
    "        else:\n",
    "            self._state[action[0]][action[1]] = 1\n",
    "        \n",
    "        full = True\n",
    "        for i in self._state:\n",
    "            for e in i:\n",
    "                if e == 0:\n",
    "                    full = False\n",
    "        \n",
    "        win = [False, False]\n",
    "        for i in range(1, 3):\n",
    "            # Row\n",
    "            for e in self._state:\n",
    "                if e[0] == i and e[1] == i and e[2] == i:\n",
    "                    win[i-1] = True\n",
    "            \n",
    "            # Column\n",
    "            for e in range(3):\n",
    "                if self._state[0][e] == i and self._state[1][e] == i and self._state[2][e] == i:\n",
    "                    win[i-1] = True\n",
    "            \n",
    "            # Diagonal\n",
    "            if self._state[0][0] == i and self._state[1][1] == i and self._state[2][2] == i:\n",
    "                win[i-1] = True\n",
    "                \n",
    "            # Anti Diagonal\n",
    "            if self._state[0][2] == i and self._state[1][1] == i and self._state[2][0] == i:\n",
    "                win[i-1] = True\n",
    "        \n",
    "        if full:\n",
    "            self._episode_ended = True\n",
    "        if win[0]:\n",
    "            self._episode_ended = True\n",
    "            reward += 20\n",
    "        if win[1]:\n",
    "            self._episode_ended = True\n",
    "            reward -= 20\n",
    "            \n",
    "        if not self._episode_ended:\n",
    "            while True:\n",
    "                x = random.randint(0, 2)\n",
    "                y = random.randint(0, 2)\n",
    "                if self._state[y][x] == 0:\n",
    "                    self._state[y][x] = 2\n",
    "                    break\n",
    "            \n",
    "        return ts.termination(np.array([self._state], dtype=np.int32), reward)\n",
    "    \n",
    "    def render(self):\n",
    "        for i in self._state:\n",
    "            row = \"\"\n",
    "            for e in i:\n",
    "                row += str(e) + \"|\"\n",
    "            print(row)\n",
    "            print(\"-|-|-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_py = Game()\n",
    "env = tf_py_environment.TFPyEnvironment(env_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0|0|0|\n",
      "-|-|-\n",
      "0|0|0|\n",
      "-|-|-\n",
      "0|0|0|\n",
      "-|-|-\n"
     ]
    }
   ],
   "source": [
    "env_py.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': array(0., dtype=float32),\n",
       " 'observation': array([[[1, 0, 2],\n",
       "        [0, 1, 0],\n",
       "        [2, 0, 1]]], dtype=int32),\n",
       " 'reward': array(20., dtype=float32),\n",
       " 'step_type': array(2, dtype=int32)})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_py._step([2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_py._episode_ended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': array(1., dtype=float32),\n",
       " 'observation': array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=int32),\n",
       " 'reward': array(0., dtype=float32),\n",
       " 'step_type': array(0, dtype=int32)})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_py.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c997253e9c9db01b2c5cb60d4f99773f770ce139bc1614a18038c034a93da84"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
