{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mnist Drawing AI\n",
    "## Version 1.0\n",
    "Das Ziel dieser AI ist es einmal ein funktionierendes Environnment zu kreieren,\n",
    "in der die KI lernen und arbeiten kann.\n",
    "\n",
    "Hierbei soll wenigstens geschaut werden, ob die AI es erlernt mal nur ein Bild\n",
    "zu zeichnen. In einer späteren Version sollen erst dann mehrere Bilder\n",
    "hineingegeben werden.\n",
    "\n",
    "Dabei soll als Input dienen:\n",
    "- Ziel Bild 28x28 -> np.shape = (784,)\n",
    "- States\n",
    "    - Canvas State 28x28 -> np.shape = (784,)\n",
    "    - Position von Agent in Space (Pen Position) -> np.shape(2,)\n",
    "\n",
    "Dabei soll der Output sein:\n",
    "- Integer\n",
    "    - Es wird immer 1, 2, 3, 4 Gezählt, welches die Himmelsrichtungen darstellt.\n",
    "    - Eine erhöhter Wert wird in den Stroke in die Länge gehen -> Bsp. 8 -> 2 Mal nach Links (Direction 4 und Length 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.environments import tf_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.environments import wrappers\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.drivers import py_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import reverb_replay_buffer\n",
    "from tf_agents.replay_buffers import reverb_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.utils import common\n",
    "from tf_agents.environments import utils\n",
    "\n",
    "import reverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 17:35:40.653448: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-20 17:35:40.673230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-20 17:35:40.673379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environnment import Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env, Model and Agent Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_py = Canvas(train_X[0])\n",
    "env = tf_py_environment.TFPyEnvironment(env_py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Actions:  16\n"
     ]
    }
   ],
   "source": [
    "fc_layer_params = (100, 50) # Die Anzahl der Dense Units in einem Layer\n",
    "action_tensor_spec = tensor_spec.from_spec(env.action_spec())\n",
    "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
    "print(\"Num Actions: \", num_actions)\n",
    "\n",
    "# Helper function um die Dense Layer zu kreeieren.\n",
    "def dense_layer(num_units):\n",
    "  return tf.keras.layers.Dense(\n",
    "      num_units,\n",
    "      activation=tf.keras.activations.relu,\n",
    "      kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
    "          scale=2.0, mode='fan_in', distribution='truncated_normal'))\n",
    "\n",
    "# Create the dense layer array\n",
    "dense_layers = [dense_layer(num_units) for num_units in fc_layer_params]\n",
    "\n",
    "# Create the output layer\n",
    "q_values_layer = tf.keras.layers.Dense(\n",
    "    num_actions,\n",
    "    activation=None,\n",
    "    kernel_initializer=tf.keras.initializers.RandomUniform(\n",
    "        minval=-0.03, maxval=0.03),\n",
    "    bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
    "\n",
    "# Sequentialize the layers into a tensorflow model\n",
    "q_net = sequential.Sequential(dense_layers + [q_values_layer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 17:35:41.294405: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-20 17:35:41.295338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-20 17:35:41.295482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-20 17:35:41.295585: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-20 17:35:41.594452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-20 17:35:41.594598: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-20 17:35:41.594707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-20 17:35:41.594810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5468 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:0b:00.0, compute capability: 8.6\n",
      "2022-04-20 17:35:42.090011: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    env.time_step_spec(),\n",
    "    env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "    total_return = 0.0\n",
    "    for _ in range(num_episodes):\n",
    "\n",
    "        time_step = environment.reset()\n",
    "        episode_return = 0.0\n",
    "\n",
    "        while not time_step.is_last():\n",
    "            action_step = policy.action(time_step)\n",
    "            time_step = environment.step(action_step.action)\n",
    "            episode_return += time_step.reward\n",
    "        total_return += episode_return\n",
    "\n",
    "    avg_return = total_return / num_episodes\n",
    "    env_py.render(\"compare\")\n",
    "    return avg_return.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "compute_avg_return(env,\n",
    "                   random_tf_policy.RandomTFPolicy(env.time_step_spec(),\n",
    "                                                   env.action_spec()),\n",
    "                   10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[reverb/cc/platform/tfrecord_checkpointer.cc:150]  Initializing TFRecordCheckpointer in /tmp/tmpe3ngdmqd.\n",
      "[reverb/cc/platform/tfrecord_checkpointer.cc:386] Loading latest checkpoint from /tmp/tmpe3ngdmqd\n",
      "[reverb/cc/platform/default/server.cc:71] Started replay server on port 15371\n"
     ]
    }
   ],
   "source": [
    "table_name = 'uniform_table'\n",
    "replay_buffer_signature = tensor_spec.from_spec(\n",
    "      agent.collect_data_spec)\n",
    "replay_buffer_signature = tensor_spec.add_outer_dim(\n",
    "    replay_buffer_signature)\n",
    "\n",
    "table = reverb.Table(\n",
    "    table_name,\n",
    "    max_size=100000,\n",
    "    sampler=reverb.selectors.Uniform(),\n",
    "    remover=reverb.selectors.Fifo(),\n",
    "    rate_limiter=reverb.rate_limiters.MinSize(1),\n",
    "    signature=replay_buffer_signature)\n",
    "\n",
    "reverb_server = reverb.Server([table])\n",
    "\n",
    "replay_buffer = reverb_replay_buffer.ReverbReplayBuffer(\n",
    "    agent.collect_data_spec,\n",
    "    table_name=table_name,\n",
    "    sequence_length=2,\n",
    "    local_server=reverb_server)\n",
    "\n",
    "rb_observer = reverb_utils.ReverbAddTrajectoryObserver(\n",
    "    replay_buffer.py_client,\n",
    "    table_name,\n",
    "    sequence_length=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TimeStep(\n",
       " {'discount': array(0.5, dtype=float32),\n",
       "  'observation': array([0, 0, 0, ..., 0, 5, 0], dtype=int32),\n",
       "  'reward': array(0., dtype=float32),\n",
       "  'step_type': array(1, dtype=int32)}),\n",
       " ())"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_driver.PyDriver(\n",
    "    env_py,\n",
    "    py_tf_eager_policy.PyTFEagerPolicy(\n",
    "        random_tf_policy.RandomTFPolicy(env.time_step_spec(),\n",
    "                                        env.action_spec()),\n",
    "        use_tf_function=True),\n",
    "        [rb_observer],\n",
    "        max_steps=100\n",
    "    ).run(env_py.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[reverb/cc/client.cc:165] Sampler and server are owned by the same process (92127) so Table uniform_table is accessed directly without gRPC.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Trajectory(\n",
       " {'action': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([5, 2], dtype=int32)>,\n",
       "  'discount': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.5, 0.5], dtype=float32)>,\n",
       "  'next_step_type': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 1], dtype=int32)>,\n",
       "  'observation': <tf.Tensor: shape=(2, 1570), dtype=int32, numpy=\n",
       " array([[ 0,  0,  0, ...,  0, 12,  9],\n",
       "        [ 0,  0,  0, ...,  0, 12, 11]], dtype=int32)>,\n",
       "  'policy_info': (),\n",
       "  'reward': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>,\n",
       "  'step_type': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 1], dtype=int32)>}),\n",
       " SampleInfo(key=<tf.Tensor: shape=(2,), dtype=uint64, numpy=array([17815610898934802805, 17815610898934802805], dtype=uint64)>, probability=<tf.Tensor: shape=(2,), dtype=float64, numpy=array([0.01030928, 0.01030928])>, table_size=<tf.Tensor: shape=(2,), dtype=int64, numpy=array([97, 97])>, priority=<tf.Tensor: shape=(2,), dtype=float64, numpy=array([1., 1.])>))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(replay_buffer.as_dataset()).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3,\n",
    "    sample_batch_size=64,\n",
    "    num_steps=2).prefetch(3)\n",
    "iterator = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f28c0144f40>\n"
     ]
    }
   ],
   "source": [
    "iterator = iter(dataset)\n",
    "print(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[reverb/cc/client.cc:165] Sampler and server are owned by the same process (92127) so Table uniform_table is accessed directly without gRPC.\n",
      "[reverb/cc/client.cc:165] Sampler and server are owned by the same process (92127) so Table uniform_table is accessed directly without gRPC.\n",
      "[reverb/cc/client.cc:165] Sampler and server are owned by the same process (92127) so Table uniform_table is accessed directly without gRPC.\n",
      "[reverb/cc/client.cc:165] Sampler and server are owned by the same process (92127) so Table uniform_table is accessed directly without gRPC.\n",
      "[reverb/cc/client.cc:165] Sampler and server are owned by the same process (92127) so Table uniform_table is accessed directly without gRPC.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Trajectory(\n",
       " {'action': <tf.Tensor: shape=(64, 2), dtype=int32, numpy=\n",
       " array([[13,  2],\n",
       "        [ 1,  8],\n",
       "        [ 7, 13],\n",
       "        [ 6,  8],\n",
       "        [ 6, 14],\n",
       "        [12, 12],\n",
       "        [ 0,  0],\n",
       "        [10,  8],\n",
       "        [ 2,  8],\n",
       "        [ 1,  5],\n",
       "        [12, 12],\n",
       "        [ 0,  2],\n",
       "        [ 1,  8],\n",
       "        [ 2, 15],\n",
       "        [11,  6],\n",
       "        [ 9,  5],\n",
       "        [ 1,  6],\n",
       "        [ 8,  2],\n",
       "        [ 0,  0],\n",
       "        [ 6,  4],\n",
       "        [ 8,  2],\n",
       "        [ 6,  4],\n",
       "        [ 5,  6],\n",
       "        [ 0, 13],\n",
       "        [15,  6],\n",
       "        [ 1,  8],\n",
       "        [ 5,  1],\n",
       "        [ 1,  6],\n",
       "        [ 3,  0],\n",
       "        [ 1,  6],\n",
       "        [ 1, 12],\n",
       "        [ 6,  4],\n",
       "        [ 2,  8],\n",
       "        [ 6, 14],\n",
       "        [ 5,  4],\n",
       "        [ 4, 12],\n",
       "        [ 2, 11],\n",
       "        [11,  6],\n",
       "        [ 2,  9],\n",
       "        [ 6,  8],\n",
       "        [ 3,  0],\n",
       "        [ 6, 15],\n",
       "        [11,  6],\n",
       "        [ 0, 12],\n",
       "        [14,  3],\n",
       "        [ 6,  4],\n",
       "        [12, 11],\n",
       "        [ 6,  8],\n",
       "        [ 5,  2],\n",
       "        [11,  0],\n",
       "        [11,  6],\n",
       "        [ 0,  6],\n",
       "        [11,  6],\n",
       "        [ 6, 12],\n",
       "        [15,  1],\n",
       "        [15,  6],\n",
       "        [ 5,  6],\n",
       "        [ 8,  2],\n",
       "        [ 6,  8],\n",
       "        [ 1,  6],\n",
       "        [ 6, 14],\n",
       "        [12, 12],\n",
       "        [15, 13],\n",
       "        [ 1,  6]], dtype=int32)>,\n",
       "  'discount': <tf.Tensor: shape=(64, 2), dtype=float32, numpy=\n",
       " array([[0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5]], dtype=float32)>,\n",
       "  'next_step_type': <tf.Tensor: shape=(64, 2), dtype=int32, numpy=\n",
       " array([[1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1]], dtype=int32)>,\n",
       "  'observation': <tf.Tensor: shape=(64, 2, 1570), dtype=int32, numpy=\n",
       " array([[[ 0,  0,  0, ...,  0, 16,  1],\n",
       "         [ 0,  0,  0, ...,  0, 16,  5]],\n",
       " \n",
       "        [[ 0,  0,  0, ...,  0, 10,  5],\n",
       "         [ 0,  0,  0, ...,  0, 10,  6]],\n",
       " \n",
       "        [[ 0,  0,  0, ...,  0,  5,  9],\n",
       "         [ 0,  0,  0, ...,  0,  5,  7]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0, ...,  0,  3,  5],\n",
       "         [ 0,  0,  0, ...,  0,  7,  5]],\n",
       " \n",
       "        [[ 0,  0,  0, ...,  0, 12,  6],\n",
       "         [ 0,  0,  0, ...,  0, 12,  2]],\n",
       " \n",
       "        [[ 0,  0,  0, ...,  0,  9,  8],\n",
       "         [ 0,  0,  0, ...,  0,  9,  9]]], dtype=int32)>,\n",
       "  'policy_info': (),\n",
       "  'reward': <tf.Tensor: shape=(64, 2), dtype=float32, numpy=\n",
       " array([[0., 1.],\n",
       "        [0., 2.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 2.],\n",
       "        [0., 0.],\n",
       "        [3., 2.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 2.],\n",
       "        [0., 0.],\n",
       "        [1., 2.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [1., 3.],\n",
       "        [0., 0.],\n",
       "        [0., 3.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [3., 2.],\n",
       "        [0., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [2., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [1., 2.]], dtype=float32)>,\n",
       "  'step_type': <tf.Tensor: shape=(64, 2), dtype=int32, numpy=\n",
       " array([[1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1]], dtype=int32)>}),\n",
       " SampleInfo(key=<tf.Tensor: shape=(64, 2), dtype=uint64, numpy=\n",
       " array([[16259008871560187754, 16259008871560187754],\n",
       "        [ 6122165911324720697,  6122165911324720697],\n",
       "        [ 9079803816011567867,  9079803816011567867],\n",
       "        [13425964726322860266, 13425964726322860266],\n",
       "        [ 2897573955855844884,  2897573955855844884],\n",
       "        [14949093563505902395, 14949093563505902395],\n",
       "        [13475506190870026765, 13475506190870026765],\n",
       "        [13718953419111947229, 13718953419111947229],\n",
       "        [ 5082665001433374846,  5082665001433374846],\n",
       "        [ 8359478730256111443,  8359478730256111443],\n",
       "        [14949093563505902395, 14949093563505902395],\n",
       "        [ 9514872031629150835,  9514872031629150835],\n",
       "        [ 6122165911324720697,  6122165911324720697],\n",
       "        [ 4621063171781045470,  4621063171781045470],\n",
       "        [ 9880908937586981932,  9880908937586981932],\n",
       "        [18003275825895711761, 18003275825895711761],\n",
       "        [ 4118323871795418570,  4118323871795418570],\n",
       "        [15710054717010633837, 15710054717010633837],\n",
       "        [13475506190870026765, 13475506190870026765],\n",
       "        [ 8811303453657889996,  8811303453657889996],\n",
       "        [15710054717010633837, 15710054717010633837],\n",
       "        [ 8811303453657889996,  8811303453657889996],\n",
       "        [17747352284192975894, 17747352284192975894],\n",
       "        [13664038024543148957, 13664038024543148957],\n",
       "        [17779836029868025550, 17779836029868025550],\n",
       "        [ 6122165911324720697,  6122165911324720697],\n",
       "        [16123362843721910021, 16123362843721910021],\n",
       "        [ 4859728397871212019,  4859728397871212019],\n",
       "        [ 8617972920038748644,  8617972920038748644],\n",
       "        [ 4118323871795418570,  4118323871795418570],\n",
       "        [10696995713375038825, 10696995713375038825],\n",
       "        [ 8811303453657889996,  8811303453657889996],\n",
       "        [ 5082665001433374846,  5082665001433374846],\n",
       "        [ 4516207639155751305,  4516207639155751305],\n",
       "        [ 6500472540033813706,  6500472540033813706],\n",
       "        [ 7462506233622167283,  7462506233622167283],\n",
       "        [  679940774093428469,   679940774093428469],\n",
       "        [16050037469913068022, 16050037469913068022],\n",
       "        [  865452642313945685,   865452642313945685],\n",
       "        [13425964726322860266, 13425964726322860266],\n",
       "        [ 8617972920038748644,  8617972920038748644],\n",
       "        [11986326787076269877, 11986326787076269877],\n",
       "        [16050037469913068022, 16050037469913068022],\n",
       "        [ 2558890387805015240,  2558890387805015240],\n",
       "        [ 7842886693754476904,  7842886693754476904],\n",
       "        [ 8811303453657889996,  8811303453657889996],\n",
       "        [ 1360864313880499633,  1360864313880499633],\n",
       "        [ 8914404675704203943,  8914404675704203943],\n",
       "        [17815610898934802805, 17815610898934802805],\n",
       "        [11997702905817578180, 11997702905817578180],\n",
       "        [16050037469913068022, 16050037469913068022],\n",
       "        [14317549971007019693, 14317549971007019693],\n",
       "        [ 9880908937586981932,  9880908937586981932],\n",
       "        [ 1181840837940626008,  1181840837940626008],\n",
       "        [ 9082067392627145375,  9082067392627145375],\n",
       "        [17779836029868025550, 17779836029868025550],\n",
       "        [17747352284192975894, 17747352284192975894],\n",
       "        [17206328878651484226, 17206328878651484226],\n",
       "        [ 8914404675704203943,  8914404675704203943],\n",
       "        [ 4118323871795418570,  4118323871795418570],\n",
       "        [ 4516207639155751305,  4516207639155751305],\n",
       "        [14949093563505902395, 14949093563505902395],\n",
       "        [15420864898145474994, 15420864898145474994],\n",
       "        [ 4859728397871212019,  4859728397871212019]], dtype=uint64)>, probability=<tf.Tensor: shape=(64, 2), dtype=float64, numpy=\n",
       " array([[0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928],\n",
       "        [0.01030928, 0.01030928]])>, table_size=<tf.Tensor: shape=(64, 2), dtype=int64, numpy=\n",
       " array([[97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97],\n",
       "        [97, 97]])>, priority=<tf.Tensor: shape=(64, 2), dtype=float64, numpy=\n",
       " array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])>))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int32, numpy=0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.train = common.function(agent.train)\n",
    "agent.train_step_counter.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = env_py.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a driver to collect experience.\n",
    "collect_driver = py_driver.PyDriver(\n",
    "    env_py,\n",
    "    py_tf_eager_policy.PyTFEagerPolicy(\n",
    "        agent.collect_policy, use_tf_function=True),\n",
    "    [rb_observer],\n",
    "    max_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 1010: loss = 0.15187905728816986\n",
      "step = 1020: loss = 0.06431002169847488\n",
      "step = 1030: loss = 0.16473202407360077\n",
      "step = 1040: loss = 0.11291304230690002\n",
      "step = 1050: loss = 0.03381148725748062\n",
      "step = 1060: loss = 0.08950655162334442\n",
      "step = 1070: loss = 0.05526487156748772\n",
      "step = 1080: loss = 0.15864576399326324\n",
      "step = 1090: loss = 0.0543067529797554\n",
      "step = 1100: loss = 0.13708165287971497\n",
      "step = 1110: loss = 0.06466031074523926\n",
      "step = 1120: loss = 0.09511271864175797\n",
      "step = 1130: loss = 0.09935254603624344\n",
      "step = 1140: loss = 0.1308666616678238\n",
      "step = 1150: loss = 0.06431138515472412\n",
      "step = 1160: loss = 0.10885657370090485\n",
      "step = 1170: loss = 0.061869941651821136\n",
      "step = 1180: loss = 0.04985601454973221\n",
      "step = 1190: loss = 0.024269767105579376\n",
      "step = 1200: loss = 0.09165126830339432\n",
      "step = 1210: loss = 0.05675877630710602\n",
      "step = 1220: loss = 0.20999465882778168\n",
      "step = 1230: loss = 0.02967820316553116\n",
      "step = 1240: loss = 0.11959823966026306\n",
      "step = 1250: loss = 0.06051928177475929\n",
      "step = 1260: loss = 0.04535864293575287\n",
      "step = 1270: loss = 0.03856015205383301\n",
      "step = 1280: loss = 0.08163569867610931\n",
      "step = 1290: loss = 0.042532943189144135\n",
      "step = 1300: loss = 0.021573655307292938\n",
      "step = 1310: loss = 0.0731707215309143\n",
      "step = 1320: loss = 0.07644146680831909\n",
      "step = 1330: loss = 0.08540119230747223\n",
      "step = 1340: loss = 0.04026731103658676\n",
      "step = 1350: loss = 0.0836709663271904\n",
      "step = 1360: loss = 0.06385277211666107\n",
      "step = 1370: loss = 0.03138531744480133\n",
      "step = 1380: loss = 0.08543415367603302\n",
      "step = 1390: loss = 0.1204889714717865\n",
      "step = 1400: loss = 0.047520801424980164\n",
      "step = 1410: loss = 0.03290632367134094\n",
      "step = 1420: loss = 0.10396502166986465\n",
      "step = 1430: loss = 0.2507435083389282\n",
      "step = 1440: loss = 0.08569744229316711\n",
      "step = 1450: loss = 0.12079256772994995\n",
      "step = 1460: loss = 0.20302465558052063\n",
      "step = 1470: loss = 0.05331289768218994\n",
      "step = 1480: loss = 0.3465713858604431\n",
      "step = 1490: loss = 0.04463839903473854\n",
      "step = 1500: loss = 0.06717315316200256\n",
      "step = 1500: Average Return = 12.0\n",
      "step = 1510: loss = 0.3002684712409973\n",
      "step = 1520: loss = 0.15779045224189758\n",
      "step = 1530: loss = 0.11642585694789886\n",
      "step = 1540: loss = 0.32808855175971985\n",
      "step = 1550: loss = 0.15029695630073547\n",
      "step = 1560: loss = 0.2624269425868988\n",
      "step = 1570: loss = 0.20636627078056335\n",
      "step = 1580: loss = 0.48821502923965454\n",
      "step = 1590: loss = 0.30895307660102844\n",
      "step = 1600: loss = 0.33827638626098633\n",
      "step = 1610: loss = 0.20866051316261292\n",
      "step = 1620: loss = 0.09516673535108566\n",
      "step = 1630: loss = 0.02172071859240532\n",
      "step = 1640: loss = 0.09210345149040222\n",
      "step = 1650: loss = 0.044163428246974945\n",
      "step = 1660: loss = 0.0673666000366211\n",
      "step = 1670: loss = 0.0545298233628273\n",
      "step = 1680: loss = 0.13389846682548523\n",
      "step = 1690: loss = 0.12540948390960693\n",
      "step = 1700: loss = 0.05516951158642769\n",
      "step = 1710: loss = 0.15963998436927795\n",
      "step = 1720: loss = 0.08677943050861359\n",
      "step = 1730: loss = 0.13766714930534363\n",
      "step = 1740: loss = 0.15846112370491028\n",
      "step = 1750: loss = 0.15488581359386444\n",
      "step = 1760: loss = 0.14216232299804688\n",
      "step = 1770: loss = 0.09419912099838257\n",
      "step = 1780: loss = 0.06241494417190552\n",
      "step = 1790: loss = 0.16316640377044678\n",
      "step = 1800: loss = 0.3436541259288788\n",
      "step = 1810: loss = 0.05792233347892761\n",
      "step = 1820: loss = 0.06082310900092125\n",
      "step = 1830: loss = 0.30233514308929443\n",
      "step = 1840: loss = 0.045871585607528687\n",
      "step = 1850: loss = 0.20061784982681274\n",
      "step = 1860: loss = 0.08686669170856476\n",
      "step = 1870: loss = 0.10420941561460495\n",
      "step = 1880: loss = 0.026144709438085556\n",
      "step = 1890: loss = 0.07960271835327148\n",
      "step = 1900: loss = 0.042086128145456314\n",
      "step = 1910: loss = 0.05390762910246849\n",
      "step = 1920: loss = 0.15075989067554474\n",
      "step = 1930: loss = 0.10885065793991089\n",
      "step = 1940: loss = 0.18476222455501556\n",
      "step = 1950: loss = 0.12312208116054535\n",
      "step = 1960: loss = 0.23552721738815308\n",
      "step = 1970: loss = 0.06866768002510071\n",
      "step = 1980: loss = 0.04250297695398331\n",
      "step = 1990: loss = 0.10333558917045593\n",
      "step = 2000: loss = 0.14053936302661896\n",
      "step = 2000: Average Return = 12.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "returns = []\n",
    "for _ in range(1000):\n",
    "    \n",
    "  # Collect a few steps and save to the replay buffer.\n",
    "  time_step, _ = collect_driver.run(time_step)\n",
    "\n",
    "  # Sample a batch of data from the buffer and update the agent's network.\n",
    "  experience, unused_info = next(iterator)\n",
    "  train_loss = agent.train(experience).loss\n",
    "\n",
    "  step = agent.train_step_counter.numpy()\n",
    "\n",
    "  if step % 10 == 0:\n",
    "    print('step = {0}: loss = {1}'.format(step, train_loss))\n",
    "\n",
    "  if step % 500 == 0:\n",
    "    avg_return = compute_avg_return(env, agent.policy, 10)\n",
    "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "    returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c997253e9c9db01b2c5cb60d4f99773f770ce139bc1614a18038c034a93da84"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
